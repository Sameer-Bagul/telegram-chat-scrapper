# ðŸ“Œ Ultimate Project Plan: Telegram Job Post Extractor

## **1. High-Level Overview**

* **Frontend (UI)** â†’ Vite + React (file upload, preview, download CSV).
* **Backend (API)** â†’ Python (FastAPI or Flask) with MVC architecture:

  * **Model** â†’ Data structures (Job Post schema).
  * **View** â†’ API responses (JSON/CSV).
  * **Controller** â†’ Orchestrates parsing, extraction, and cleaning.
* **Data Processing Layer** â†’ Python libraries for parsing HTML, extracting structured job details.
* **Storage** â†’ Optional (CSV only or extend to DB like PostgreSQL/SQLite).

---

## **2. Tech Stack**

### **Frontend**

* **Vite + React (TypeScript)**
* UI Components: TailwindCSS / Material UI
* Features:

  * Upload `.html` file
  * Display parsed job data preview
  * Download as `.csv`

### **Backend (Python)**

* **Framework**: FastAPI (best for APIs, async, clean structure)
* **Libraries**:

  * `beautifulsoup4 + lxml` â†’ Parse Telegram HTML
  * `re` â†’ Regex for emails, links, phone
  * `phonenumbers` â†’ Validate phone numbers
  * `email-validator` â†’ Validate emails
  * `pandas` â†’ Data structuring
  * `dateutil` â†’ Date parsing
  * *(Optional)* `spaCy` â†’ Extract job titles, company, location

---

## **3. Backend Architecture (MVC)**

```
backend/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ models/               # Data schemas
â”‚   â”‚   â”œâ”€â”€ job_post.py       # JobPost schema (Pydantic)
â”‚   â”‚
â”‚   â”œâ”€â”€ views/                # API layer
â”‚   â”‚   â”œâ”€â”€ job_routes.py     # Endpoints (upload, download)
â”‚   â”‚
â”‚   â”œâ”€â”€ controllers/          # Business logic
â”‚   â”‚   â”œâ”€â”€ job_controller.py # Parsing + extraction logic
â”‚   â”‚
â”‚   â”œâ”€â”€ services/             # Utility modules
â”‚   â”‚   â”œâ”€â”€ parser.py         # HTML parser
â”‚   â”‚   â”œâ”€â”€ extractor.py      # Regex/NLP extractors
â”‚   â”‚   â”œâ”€â”€ cleaner.py        # Validation & formatting
â”‚   â”‚   â”œâ”€â”€ exporter.py       # CSV export
â”‚   â”‚
â”‚   â”œâ”€â”€ main.py               # FastAPI entrypoint
â”‚
â”‚â”€â”€ requirements.txt
```

---

## **4. Frontend Architecture**

```
frontend/
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ FileUpload.tsx      # Upload button
â”‚   â”‚   â”œâ”€â”€ JobTable.tsx        # Preview table
â”‚   â”‚   â”œâ”€â”€ DownloadButton.tsx  # Download CSV
â”‚   â”‚
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ Home.tsx            # Main UI
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ api.ts              # Axios API calls to backend
â”‚   â”‚
â”‚   â”œâ”€â”€ App.tsx
â”‚â”€â”€ vite.config.ts
```

---

## **5. Workflow**

### **Frontend Flow**

1. User opens the website (Vite app).
2. Uploads Telegram HTML export.
3. File is sent via **POST /upload** API to backend.
4. Backend parses, extracts, cleans data.
5. Frontend displays **preview table** of extracted jobs.
6. User clicks "Download CSV" â†’ triggers **GET /download** API.

### **Backend Flow**

1. **Upload Handler** receives HTML file.
2. **Controller** calls parser + extractor.
3. **Extractor** finds emails, phone numbers, job titles, company, etc.
4. **Cleaner** validates & normalizes data.
5. **Model** (JobPost) structures it.
6. **Exporter** saves as CSV in memory.
7. **API Response** â†’ JSON (for preview) + CSV (for download).

---

## **6. API Endpoints**

### **POST /upload**

* Input: HTML file (multipart form).
* Output: JSON array of job postings.

```json
[
  {
    "name": "John Doe",
    "email": "hr@example.com",
    "phone": "+1-202-555-0123",
    "job_title": "Software Engineer",
    "company": "TechCorp",
    "location": "New York",
    "date_of_posting": "2025-09-20",
    "job_description": "Looking for Python developers...",
    "link": "https://example.com/job123",
    "notes": ""
  }
]
```

### **GET /download**

* Returns: CSV file of the latest parsed job postings.

---

## **7. Project Roadmap**

### **Phase 1: Backend Core**

* Implement **HTML parsing + extraction**.
* Return **JSON response** for preview.
* Save **CSV locally**.

### **Phase 2: Frontend Integration**

* Build Vite frontend.
* File upload + API call.
* Display parsed results in table.

### **Phase 3: CSV Download**

* Add backend CSV download endpoint.
* Frontend "Download CSV" button.

### **Phase 4: Advanced Features**

* NLP-based job title, company, and location extraction.
* Duplicate removal.
* Store history in a database (optional).

---

## **8. Deployment**

* **Backend** â†’ Dockerized FastAPI app (host on AWS/GCP/Heroku).
* **Frontend** â†’ Build Vite app â†’ Deploy on Vercel/Netlify.
* **CORS** â†’ Enable communication between frontend & backend.

---

ðŸ”¥ With this setup, youâ€™ll have:

* A clean **MVC Python backend**.
* A modern **Vite + React frontend**.
* Upload â†’ Preview â†’ Download CSV workflow.
* Scalable foundation for NLP/DB in future.

---

ðŸ‘‰ Do you want me to **first draft the backend MVC skeleton** (folders, FastAPI endpoints, basic parser), or the **frontend Vite structure with API hooks**?
